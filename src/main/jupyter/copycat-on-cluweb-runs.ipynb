{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CopyCat: Example Usage on the Web Track Runs\n",
    "\n",
    "- Use cases of CopyCat:\n",
    "  - Precision oriented deduplication on complete corpora with Spark/Hadoop\n",
    "  - Lossless near-duplicate detection to improve recall while maintaining high precision on small document sets (run/qrel files) on your laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: CopyCat: Deduplication of run files and qrels.\r\n",
      "       [-h] --input INPUT --output OUTPUT\r\n",
      "       [--similarities {url,s3,cosine(3+5-grams),cosine(8-grams),cosine(1-grams),simhash(1-grams),simhash(3+5-grams),md5,text-profile} [{url,s3,cosine(3+5-grams),cosine(8-grams),cosine(1-grams),simhash(1-grams),simhash(3+5-grams),md5,text-profile} ...]]\r\n",
      "       [--stringTransformation STRINGTRANSFORMATION]\r\n",
      "       --documents {ChatNoirMapfiles,AnseriniIndex}\r\n",
      "       [--anseriniIndex ANSERINIINDEX] [--ranks RANKS]\r\n",
      "       [--s3Threshold S3THRESHOLD] [--threads THREADS]\r\n",
      "\r\n",
      "named arguments:\r\n",
      "  -h, --help             show this help message and exit\r\n",
      "  --input INPUT          The  run  file  or   qrel   file  that  should  be\r\n",
      "                         deduplicated.\r\n",
      "  --output OUTPUT        The result of the deduplication in jsonl format.\r\n",
      "  --similarities {url,s3,cosine(3+5-grams),cosine(8-grams),cosine(1-grams),simhash(1-grams),simhash(3+5-grams),md5,text-profile} [{url,s3,cosine(3+5-grams),cosine(8-grams),cosine(1-grams),simhash(1-grams),simhash(3+5-grams),md5,text-profile} ...]\r\n",
      "                         Calculate all passed similarities.\r\n",
      "  --stringTransformation STRINGTRANSFORMATION\r\n",
      "                         The  anserini  StringTransform  that  is  used  to\r\n",
      "                         transform the raw document  into text. The default\r\n",
      "                         is  JsoupStringTransform,  which   uses  Jsoup  to\r\n",
      "                         extract plain text out of HTML documents.\r\n",
      "  --documents {ChatNoirMapfiles,AnseriniIndex}\r\n",
      "                         Use  the  passed  DocumentResolver   to  load  the\r\n",
      "                         documents. E.g. AnseriniIndex  loads  documents by\r\n",
      "                         accessing a local anserini-index.\r\n",
      "  --anseriniIndex ANSERINIINDEX\r\n",
      "                         When   using   AnseriniIndex   as   resolver   for\r\n",
      "                         documents, we use the specified index.\r\n",
      "  --ranks RANKS          Include documents up to the  specified rank in the\r\n",
      "                         deduplication.\r\n",
      "  --s3Threshold S3THRESHOLD\r\n",
      "                         Report only near-duplicate  pairs  with  s3 scores\r\n",
      "                         on word 8-grams above the specified threshold.\r\n",
      "  --threads THREADS\r\n"
     ]
    }
   ],
   "source": [
    "# Show Usage of copy cat.\n",
    "!../bash/copy-cat.sh -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SERP Deduplication\n",
    "\n",
    "- Situation:\n",
    "  - Near-Duplicates are removed from the Index\n",
    "    - With SimHash (3+5-grams) + Canonical-URL\n",
    "\n",
    "- Is it still necessary to remove near-duplicates from the SERP?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP: SERP Deduplication for a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specified output 'run-UAMSA10d2a8-deduplication.jsonl' exists.\r\n",
      "Skip...\r\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate a single run-file (please remove the output file to run copy-cat from scratch)\n",
    "\n",
    "!../bash/copy-cat.sh \\\n",
    "    --output run-UAMSA10d2a8-deduplication.jsonl \\\n",
    "    --input input.UAMSA10d2a8 \\\n",
    "    --similarities \"url s3 cosine(3+5-grams) cosine(8-grams) cosine(1-grams) simhash(1-grams) simhash(3+5-grams) md5 text-profile\" \\\n",
    "    --s3Threshold 0.7 \\\n",
    "    --threads 5 \\\n",
    "    --documents ChatNoirMapfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from trectools import TrecQrel\n",
    "\n",
    "qrels = TrecQrel('qrels.web.101-150.txt')\n",
    "\n",
    "def eval_with_threshold(threshold, run_file_name):\n",
    "    rows = []\n",
    "    with open(run_file_name) as jsonl_file:\n",
    "        for jsonl in jsonl_file:\n",
    "            dedup_data = json.loads(jsonl)\n",
    "            topic = dedup_data['topic']\n",
    "            judged_docs = qrels.get_document_names_for_topic(int(topic))\n",
    "            \n",
    "            for sim in dedup_data['similarities']:\n",
    "                is_judged = sim['firstId'] in judged_docs or sim['secondId'] in judged_docs\n",
    "                is_relevant = False\n",
    "                is_irrelevant = False\n",
    "                \n",
    "                if is_judged:\n",
    "                    judgment_a = qrels.get_judgement(sim['firstId'], int(topic))\n",
    "                    judgment_b = qrels.get_judgement(sim['secondId'], int(topic))\n",
    "                    is_irrelevant = judgment_a == 0 or judgment_b == 0\n",
    "                    is_relevant = not is_irrelevant\n",
    "                \n",
    "                rows += [{\n",
    "                    'topic': topic,\n",
    "                    'judged': is_judged,\n",
    "                    'relevant': is_relevant,\n",
    "                    'irrelevant': is_irrelevant,\n",
    "                    'near-duplicate': sim['similarities']['s3'] >=  threshold,\n",
    "                    'simhash(3+5-grams)': sim['similarities']['simhash(3+5-grams)'] > 0.94,\n",
    "                    'simhash(1-grams)': sim['similarities']['simhash(1-grams)'] > 0.94,\n",
    "                    'url': sim['similarities']['url'] > 0.5,\n",
    "                    'text-profile': sim['similarities']['text-profile'] > 0.5,\n",
    "                    'md5': sim['similarities']['md5'] > 0.5,\n",
    "                    'copy-cat': ((sim['similarities']['simhash(3+5-grams)'] > 0.94) or ((sim['similarities']['url'] > 0.5) and (sim['similarities']['simhash(1-grams)'] > 0.94))),\n",
    "                    'copy-cat-tp': ((sim['similarities']['simhash(3+5-grams)'] > 0.94) or (sim['similarities']['text-profile'] > 0.5) or ((sim['similarities']['url'] > 0.5) and (sim['similarities']['simhash(1-grams)'] > 0.94)))\n",
    "                }]\n",
    "\n",
    "    return rows\n",
    "\n",
    "def eval_runs_with_threshold(threshold, run_files):\n",
    "    rows = []\n",
    "    for r in run_files:\n",
    "        rows += eval_with_threshold(threshold, r)\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEDUP_TARGET_DIR='../../../top-100-deduplication/'\n",
    "ALL_DIRS=!ls $DEDUP_TARGET_DIR\n",
    "ALL_DIRS=!ls $DEDUP_TARGET_DIR\n",
    "ALL_DIRS = [DEDUP_TARGET_DIR + i for i in ALL_DIRS]\n",
    "\n",
    "\n",
    "df = eval_runs_with_threshold(0.82, ALL_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision/Recall with S3 score as ground-truth (small cw09 sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Top100</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Relevant@Top100</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Irrelevant@Top100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CopyCat</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimHash(1-grams)</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SimHash(3+5-grams)</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextProfile</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.383</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MD5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Approach    Top100        Relevant@Top100         \\\n",
       "                      Precision Recall       Precision Recall   \n",
       "0             CopyCat     0.997  0.701           0.998  0.836   \n",
       "1    SimHash(1-grams)     0.932  0.792           0.952  0.961   \n",
       "2  SimHash(3+5-grams)     0.998  0.589           1.000  0.689   \n",
       "3         TextProfile     0.998  0.305           0.996  0.383   \n",
       "4                 MD5     1.000  0.135           1.000  0.239   \n",
       "\n",
       "  Irrelevant@Top100         \n",
       "          Precision Recall  \n",
       "0             0.996  0.634  \n",
       "1             0.958  0.759  \n",
       "2             0.997  0.537  \n",
       "3             1.000  0.250  \n",
       "4             1.000  0.147  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_score(df, approach):\n",
    "    from sklearn.metrics import precision_score\n",
    "    return \"{:0.3f}\".format(precision_score(y_true=df['near-duplicate'], y_pred=df[approach]))\n",
    "\n",
    "def recall_score(df, approach):\n",
    "    from sklearn.metrics import recall_score\n",
    "    return \"{:0.3f}\".format(recall_score(y_true=df['near-duplicate'], y_pred=df[approach]))\n",
    "\n",
    "def table_row(df, approach, approach_display_name):\n",
    "    df_relevant_100 = df[(df['judged']) & (df['relevant'])]\n",
    "    df_irrelevant_100 = df[(df['judged']) & (~df['relevant'])]\n",
    "\n",
    "    return {\n",
    "        'Approach': approach_display_name,\n",
    "        'Precision (Top100)': precision_score(df, approach),\n",
    "        'Recall (Top100)': recall_score(df, approach),\n",
    "        'Precision (Relevant@Top100)': precision_score(df_relevant_100, approach),\n",
    "        'Recall (Relevant@Top100': recall_score(df_relevant_100, approach),\n",
    "        'Precision (Irrelevant@Top100)': precision_score(df_irrelevant_100, approach),\n",
    "        'Recall (Irrelevant@Top100)': recall_score(df_irrelevant_100, approach),\n",
    "    }\n",
    "\n",
    "def report_table(df):\n",
    "    rows = []\n",
    "    for approach, approach_display_name in [('copy-cat-tp', 'CopyCat'), ('simhash(1-grams)', 'SimHash(1-grams)'), ('simhash(3+5-grams)', 'SimHash(3+5-grams)'), ('text-profile', 'TextProfile') , ('md5', 'MD5')]:\n",
    "        rows += [table_row(df, approach, approach_display_name)]\n",
    "    ret = pd.DataFrame(rows)\n",
    "    ret.set_index('Approach', inplace=True)\n",
    "    ret.columns = pd.MultiIndex.from_tuples([\n",
    "        ('Top100', 'Precision'), ('Top100', 'Recall'),\n",
    "        ('Relevant@Top100', 'Precision'), ('Relevant@Top100', 'Recall'),\n",
    "        ('Irrelevant@Top100', 'Precision'), ('Irrelevant@Top100', 'Recall'),\n",
    "    ])\n",
    "\n",
    "    return ret.reset_index()\n",
    "\n",
    "print('Precision/Recall with S3 score as ground-truth (small cw09 sample):')\n",
    "report_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "- Improve efficiency of \"local\" copy-cat\n",
    "- Evaluations:\n",
    "  - Add top 1000 to the table above\n",
    "  - At which Positions occur duplicates?\n",
    "    - Duplicates within the top k\n",
    "- Evaluation Notebooks (all available runs):\n",
    "  - ClueWeb\n",
    "  - Robust04\n",
    "  - Argsme\n",
    "- Relevance Transfer:\n",
    "  - Deduplicate on the top-10000 results for each topic with CopyCat\n",
    "- Finish Anserini-Integration\n",
    "  - Use jigsaw modules to separate ChatNoir from Anserini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
