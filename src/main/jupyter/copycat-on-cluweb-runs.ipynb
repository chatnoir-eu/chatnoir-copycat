{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CopyCat: Example Usage on the Web Track Runs\n",
    "\n",
    "- Use cases of CopyCat:\n",
    "  - Precision oriented deduplication on complete corpora with Spark/Hadoop\n",
    "  - Lossless near-duplicate detection to improve recall while maintaining high precision on small document sets (run/qrel files) on your laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR='/mnt/ceph/storage/data-in-progress/data-research/web-search/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREC 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process '/mnt/ceph/storage/data-in-progress/data-research/web-search/web-search-trec/trec-system-runs/trec20/web.adhoc//input.2011SiftR1.gz' to '/mnt/ceph/storage/data-in-progress/data-research/web-search/SIGIR-21/sigir21-deduplicate-trec-run-files/trec20-web.adhoc-top100/2011SiftR1.jsonl'.\n",
      "Process topic 101\n",
      "log4j:WARN No such property [maxBackupIndex] in org.apache.log4j.DailyRollingFileAppender.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/workdir/copycat-cli/target/copycat-cli-1.0-SNAPSHOT-jar-with-dependencies.jar) to method sun.security.krb5.Config.getInstance()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Retrieving clueweb09-en0006-70-22555 took: 3414\n",
      "Retrieving clueweb09-en0003-60-13052 took: 3915\n",
      "Retrieving clueweb09-en0008-72-29938 took: 3903\n",
      "Retrieving clueweb09-en0003-75-17857 took: 491\n",
      "Retrieving clueweb09-en0006-70-22560 took: 1468\n",
      "Retrieving clueweb09-en0007-97-25998 took: 5161\n",
      "Retrieving clueweb09-en0010-93-32796 took: 5789\n",
      "Retrieving clueweb09-en0006-70-22562 took: 2007\n",
      "Retrieving clueweb09-en0004-37-01154 took: 2504\n",
      "Retrieving clueweb09-en0011-32-10146 took: 1729\n",
      "Retrieving clueweb09-en0008-78-08029 took: 3859\n",
      "Retrieving clueweb09-en0002-83-01420 took: 2732\n",
      "Retrieving clueweb09-en0011-32-10186 took: 2829\n",
      "Retrieving clueweb09-en0007-97-25999 took: 5193\n",
      "Retrieving clueweb09-en0008-80-29984 took: 3093\n",
      "Retrieving clueweb09-en0007-97-26000 took: 1859\n",
      "Retrieving clueweb09-en0002-98-11102 took: 2908\n",
      "Retrieving clueweb09-en0008-24-24500 took: 1790\n",
      "Retrieving clueweb09-en0006-70-22566 took: 7429\n",
      "Retrieving clueweb09-en0003-60-13047 took: 1968\n",
      "Retrieving clueweb09-en0010-91-25316 took: 4184\n",
      "Retrieving clueweb09-en0007-97-26001 took: 2867\n",
      "Retrieving clueweb09-en0008-50-34897 took: 2525\n",
      "Retrieving clueweb09-en0004-79-15466 took: 2724\n",
      "Retrieving clueweb09-en0006-70-22568 took: 3729\n",
      "Retrieving clueweb09-en0010-93-30671 took: 3787\n",
      "Retrieving clueweb09-en0007-97-26261 took: 3513\n",
      "Retrieving clueweb09-en0005-83-31893 took: 1821\n",
      "Retrieving clueweb09-en0008-51-28018 took: 5173\n",
      "Retrieving clueweb09-en0006-70-22577 took: 2960\n",
      "Retrieving clueweb09-en0008-24-24493 took: 2446\n",
      "Retrieving clueweb09-en0006-37-16979 took: 2112\n",
      "Retrieving clueweb09-en0010-93-30940 took: 3269\n",
      "Retrieving clueweb09-en0006-70-22515 took: 719\n",
      "Retrieving clueweb09-en0006-97-01938 took: 1048\n",
      "Retrieving clueweb09-en0008-90-41002 took: 1617\n",
      "Retrieving clueweb09-en0006-51-35681 took: 1774\n",
      "Retrieving clueweb09-en0004-44-12378 took: 775\n",
      "Retrieving clueweb09-en0006-70-22517 took: 2353\n",
      "Retrieving clueweb09-en0011-83-34136 took: 2762\n",
      "Retrieving clueweb09-en0011-98-14876 took: 644\n",
      "Retrieving clueweb09-en0007-65-25377 took: 2911\n",
      "Retrieving clueweb09-en0009-14-05238 took: 2886\n",
      "Retrieving clueweb09-en0006-70-22523 took: 2146\n",
      "Retrieving clueweb09-enwp01-10-20426 took: 1650\n",
      "Retrieving clueweb09-en0007-71-07471 took: 2080\n",
      "Retrieving clueweb09-en0009-15-15863 took: 2438\n",
      "Retrieving clueweb09-en0004-66-09322 took: 4364\n",
      "Retrieving clueweb09-enwp01-40-22507 took: 1629\n",
      "Retrieving clueweb09-en0006-70-22678 took: 1268\n",
      "Retrieving clueweb09-en0006-70-22496 took: 2704\n",
      "Retrieving clueweb09-en0006-80-16991 took: 1356\n",
      "Retrieving clueweb09-en0009-17-05479 took: 2202\n",
      "Retrieving clueweb09-en0011-32-10292 took: 1631\n",
      "Retrieving clueweb09-en0006-83-31753 took: 440\n",
      "Retrieving clueweb09-en0011-50-37385 took: 604\n",
      "Retrieving clueweb09-en0011-52-14199 took: 1210\n",
      "Retrieving clueweb09-en0001-91-27453 took: 1726\n",
      "Retrieving clueweb09-en0006-70-22500 took: 3554\n",
      "Retrieving clueweb09-en0004-75-27659 took: 4643\n",
      "Retrieving clueweb09-en0008-86-11031 took: 3218\n",
      "Retrieving clueweb09-en0001-98-07420 took: 2640\n",
      "Retrieving clueweb09-en0008-86-11051 took: 1652\n",
      "Retrieving clueweb09-en0006-70-22624 took: 1967\n",
      "Retrieving clueweb09-en0006-70-22626 took: 574\n",
      "Retrieving clueweb09-en0006-70-22506 took: 3467\n",
      "Retrieving clueweb09-en0009-42-25680 took: 622\n",
      "Retrieving clueweb09-en0010-39-17891 took: 5259\n",
      "Retrieving clueweb09-en0002-26-21862 took: 2916\n",
      "Retrieving clueweb09-en0009-83-31721 took: 1099\n",
      "Retrieving clueweb09-en0008-90-16355 took: 3037\n",
      "Retrieving clueweb09-en0010-88-00029 took: 973\n",
      "Retrieving clueweb09-en0010-42-03657 took: 2016\n",
      "Retrieving clueweb09-en0006-70-22627 took: 3964\n",
      "Retrieving clueweb09-en0002-46-20098 took: 2249\n",
      "Retrieving clueweb09-en0010-91-25089 took: 995\n",
      "Retrieving clueweb09-en0010-37-40536 took: 2152\n",
      "Retrieving clueweb09-en0002-54-00468 took: 797\n",
      "Retrieving clueweb09-en0009-19-09264 took: 1250\n",
      "Retrieving clueweb09-en0006-70-22638 took: 2333\n",
      "Retrieving clueweb09-en0010-42-04786 took: 3583\n",
      "Retrieving clueweb09-en0006-70-22597 took: 488\n",
      "Retrieving clueweb09-en0002-62-17931 took: 3035\n",
      "Retrieving clueweb09-en0006-70-22653 took: 1951\n",
      "Retrieving clueweb09-en0010-91-25096 took: 4066\n",
      "Retrieving clueweb09-en0000-79-12800 took: 874\n",
      "Retrieving clueweb09-en0009-19-09281 took: 3483\n",
      "Retrieving clueweb09-en0006-70-22608 took: 2416\n",
      "Retrieving clueweb09-en0006-70-22658 took: 2242\n",
      "Retrieving clueweb09-en0001-69-04553 took: 2225\n",
      "Retrieving clueweb09-en0006-70-22659 took: 1559\n",
      "Retrieving clueweb09-en0001-74-36490 took: 1053\n",
      "Retrieving clueweb09-en0006-70-22613 took: 2583\n",
      "Retrieving clueweb09-en0009-39-12311 took: 4584\n",
      "Retrieving clueweb09-en0000-11-36944 took: 2252\n",
      "Retrieving clueweb09-en0006-70-22583 took: 3903\n",
      "Retrieving clueweb09-en0000-21-12356 took: 2490\n",
      "Retrieving clueweb09-en0006-70-22588 took: 1864\n",
      "Retrieving clueweb09-en0000-78-19663 took: 2142\n",
      "Retrieving clueweb09-en0006-70-22594 took: 1677\n",
      "^C\n",
      "Process '/mnt/ceph/storage/data-in-progress/data-research/web-search/web-search-trec/trec-system-runs/trec20/web.adhoc//input.2011SiftR2.gz' to '/mnt/ceph/storage/data-in-progress/data-research/web-search/SIGIR-21/sigir21-deduplicate-trec-run-files/trec20-web.adhoc-top100/2011SiftR2.jsonl'.\n",
      "Process topic 101\n",
      "log4j:WARN No such property [maxBackupIndex] in org.apache.log4j.DailyRollingFileAppender.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/workdir/copycat-cli/target/copycat-cli-1.0-SNAPSHOT-jar-with-dependencies.jar) to method sun.security.krb5.Config.getInstance()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Retrieving clueweb09-en0007-71-07471 took: 3811\n",
      "Retrieving clueweb09-en0010-93-30940 took: 3831\n",
      "Retrieving clueweb09-en0010-37-40536 took: 3718\n",
      "Retrieving clueweb09-en0006-70-22560 took: 4120\n",
      "Retrieving clueweb09-en0008-51-28018 took: 4160\n",
      "Retrieving clueweb09-en0008-51-28078 took: 1579\n",
      "Retrieving clueweb09-en0011-32-10146 took: 1911\n",
      "Retrieving clueweb09-en0007-97-25998 took: 2715\n",
      "^C\n",
      "java.io.IOException: Filesystem closed\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)\n",
      "\tat java.base/java.io.FilterInputStream.close(FilterInputStream.java:180)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.close(SequenceFile.java:2069)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.readIndex(MapFile.java:511)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:591)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:573)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.seek(MapFile.java:560)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.get(MapFile.java:679)\n",
      "\tat de.webis.chatnoir2.webclient.hdfs.MapFileReader.getDocument(MapFileReader.java:136)\n",
      "\tat de.webis.chatnoir2.webclient.search.DocumentRetriever.getByUUID(DocumentRetriever.java:131)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.doc(CollectionDocumentUtil.java:211)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.loadCollectionDocument(CollectionDocumentUtil.java:179)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver$1.loadCollectionDocument(CollectionDocumentUtil.java:220)\n",
      "\tat de.webis.copycat_cli.doc_resolver.ChatNoirDocumentResolver.loadCollectionDocument(ChatNoirDocumentResolver.java:13)\n",
      "\tat de.webis.cikm20_duplicates.app.DeduplicateTrecRunFile.lambda$docs$1(DeduplicateTrecRunFile.java:92)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)\n",
      "\tat java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926)\n",
      "\tat java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327)\n",
      "\tat java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n",
      "Retrieving clueweb09-en0006-70-22562 took: 2875\n",
      "java.io.IOException: Filesystem closed\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)\n",
      "\tat java.base/java.io.DataInputStream.readFully(DataInputStream.java:200)\n",
      "\tat org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:70)\n",
      "\tat org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:120)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.readBuffer(SequenceFile.java:2151)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.seekToCurrentValue(SequenceFile.java:2217)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.getCurrentValue(SequenceFile.java:2253)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.get(MapFile.java:680)\n",
      "\tat de.webis.chatnoir2.webclient.hdfs.MapFileReader.getDocument(MapFileReader.java:136)\n",
      "\tat de.webis.chatnoir2.webclient.search.DocumentRetriever.getByUUID(DocumentRetriever.java:131)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.doc(CollectionDocumentUtil.java:211)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.loadCollectionDocument(CollectionDocumentUtil.java:179)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver$1.loadCollectionDocument(CollectionDocumentUtil.java:220)\n",
      "\tat de.webis.copycat_cli.doc_resolver.ChatNoirDocumentResolver.loadCollectionDocument(ChatNoirDocumentResolver.java:13)\n",
      "\tat de.webis.cikm20_duplicates.app.DeduplicateTrecRunFile.lambda$docs$1(DeduplicateTrecRunFile.java:92)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)\n",
      "\tat java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926)\n",
      "\tat java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327)\n",
      "\tat java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:408)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:736)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceOp.evaluateParallel(ReduceOps.java:919)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\n",
      "\tat java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)\n",
      "\tat de.webis.cikm20_duplicates.app.DeduplicateTrecRunFile.lambda$docs$2(DeduplicateTrecRunFile.java:92)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask$AdaptedCallable.exec(ForkJoinTask.java:1448)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n",
      "Retrieving clueweb09-en0008-72-29938 took: 1271\n",
      "java.io.IOException: Filesystem closed\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)\n",
      "\tat java.base/java.io.FilterInputStream.close(FilterInputStream.java:180)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.close(SequenceFile.java:2069)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.readIndex(MapFile.java:511)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:591)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.seekInternal(MapFile.java:573)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.seek(MapFile.java:560)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.get(MapFile.java:679)\n",
      "\tat de.webis.chatnoir2.webclient.hdfs.MapFileReader.getDocument(MapFileReader.java:136)\n",
      "\tat de.webis.chatnoir2.webclient.search.DocumentRetriever.getByUUID(DocumentRetriever.java:131)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.doc(CollectionDocumentUtil.java:211)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.loadCollectionDocument(CollectionDocumentUtil.java:179)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver$1.loadCollectionDocument(CollectionDocumentUtil.java:220)\n",
      "\tat de.webis.copycat_cli.doc_resolver.ChatNoirDocumentResolver.loadCollectionDocument(ChatNoirDocumentResolver.java:13)\n",
      "\tat de.webis.cikm20_duplicates.app.DeduplicateTrecRunFile.lambda$docs$1(DeduplicateTrecRunFile.java:92)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)\n",
      "\tat java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926)\n",
      "\tat java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327)\n",
      "\tat java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n",
      "Retrieving clueweb09-en0010-39-17891 took: 3058\n",
      "java.io.IOException: Filesystem closed\n",
      "\tat org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)\n",
      "\tat org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:735)\n",
      "\tat java.base/java.io.DataInputStream.readByte(DataInputStream.java:270)\n",
      "\tat org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)\n",
      "\tat org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)\n",
      "\tat org.apache.hadoop.io.Text.readString(Text.java:471)\n",
      "\tat org.apache.hadoop.io.Text.readString(Text.java:464)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1936)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1880)\n",
      "\tat org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1829)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:443)\n",
      "\tat org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:399)\n",
      "\tat de.webis.chatnoir2.webclient.hdfs.MapFileReader.getDocument(MapFileReader.java:132)\n",
      "\tat de.webis.chatnoir2.webclient.search.DocumentRetriever.getByUUID(DocumentRetriever.java:131)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.doc(CollectionDocumentUtil.java:211)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver.loadCollectionDocument(CollectionDocumentUtil.java:179)\n",
      "\tat de.webis.cikm20_duplicates.util.CollectionDocumentUtil$HdfsMapFileDocumentResolver$1.loadCollectionDocument(CollectionDocumentUtil.java:220)\n",
      "\tat de.webis.copycat_cli.doc_resolver.ChatNoirDocumentResolver.loadCollectionDocument(ChatNoirDocumentResolver.java:13)\n",
      "\tat de.webis.cikm20_duplicates.app.DeduplicateTrecRunFile.lambda$docs$1(DeduplicateTrecRunFile.java:92)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)\n",
      "\tat java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:952)\n",
      "\tat java.base/java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:926)\n",
      "\tat java.base/java.util.stream.AbstractTask.compute(AbstractTask.java:327)\n",
      "\tat java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746)\n",
      "\tat java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)\n",
      "\tat java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)\n",
      "\tat java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)\n",
      "Retrieving clueweb09-en0007-97-25999 took: 519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process '/mnt/ceph/storage/data-in-progress/data-research/web-search/web-search-trec/trec-system-runs/trec20/web.adhoc//input.2011SiftR3.gz' to '/mnt/ceph/storage/data-in-progress/data-research/web-search/SIGIR-21/sigir21-deduplicate-trec-run-files/trec20-web.adhoc-top100/2011SiftR3.jsonl'.\n",
      "Process topic 101\n",
      "log4j:WARN No such property [maxBackupIndex] in org.apache.log4j.DailyRollingFileAppender.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/workdir/copycat-cli/target/copycat-cli-1.0-SNAPSHOT-jar-with-dependencies.jar) to method sun.security.krb5.Config.getInstance()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Retrieving clueweb09-en0008-80-30022 took: 4182\n",
      "Retrieving clueweb09-en0008-54-15954 took: 4181\n",
      "Retrieving clueweb09-en0004-66-09322 took: 4859\n",
      "Retrieving clueweb09-en0011-32-10146 took: 4610\n",
      "Retrieving clueweb09-en0009-19-09264 took: 5785\n",
      "Retrieving clueweb09-en0004-97-01606 took: 2099\n",
      "Retrieving clueweb09-en0008-82-30566 took: 2871\n",
      "Retrieving clueweb09-en0008-72-29938 took: 2969\n",
      "Retrieving clueweb09-en0009-62-01021 took: 1934\n",
      "Retrieving clueweb09-en0011-32-10186 took: 2920\n",
      "Retrieving clueweb09-en0005-83-31893 took: 1759\n",
      "Retrieving clueweb09-en0008-82-30606 took: 2235\n",
      "Retrieving clueweb09-en0008-80-29979 took: 2627\n",
      "Retrieving clueweb09-en0009-83-31721 took: 2063\n",
      "Retrieving clueweb09-en0010-05-10712 took: 603\n",
      "Retrieving clueweb09-en0008-80-29983 took: 789\n",
      "Retrieving clueweb09-en0011-32-10292 took: 2776\n",
      "Retrieving clueweb09-en0008-85-37533 took: 405\n",
      "Retrieving clueweb09-en0008-80-29999 took: 1601\n",
      "Retrieving clueweb09-en0005-85-00514 took: 2835\n",
      "Retrieving clueweb09-en0008-80-29984 took: 1619\n",
      "Retrieving clueweb09-en0008-80-30000 took: 1384\n",
      "Retrieving clueweb09-en0010-93-29474 took: 3122\n",
      "Retrieving clueweb09-en0008-80-29992 took: 1747\n",
      "Retrieving clueweb09-en0008-80-30010 took: 2159\n",
      "Retrieving clueweb09-en0008-86-11031 took: 4554\n",
      "Retrieving clueweb09-en0010-93-30671 took: 1890\n",
      "Retrieving clueweb09-en0007-97-25999 took: 1870\n",
      "Retrieving clueweb09-en0007-65-25377 took: 1408\n",
      "Retrieving clueweb09-en0008-86-11051 took: 577\n",
      "Retrieving clueweb09-en0006-11-05235 took: 5184\n",
      "Retrieving clueweb09-en0008-50-34897 took: 1302\n",
      "Retrieving clueweb09-en0007-70-02732 took: 2278\n",
      "Retrieving clueweb09-en0007-75-35445 took: 671\n",
      "Retrieving clueweb09-en0001-74-36490 took: 3112\n",
      "Retrieving clueweb09-en0006-51-35681 took: 2590\n",
      "Retrieving clueweb09-en0008-51-28018 took: 2313\n",
      "Retrieving clueweb09-en0011-31-18792 took: 4659\n",
      "Retrieving clueweb09-en0001-91-27453 took: 1809\n",
      "Retrieving clueweb09-en0003-75-17857 took: 1765\n",
      "Retrieving clueweb09-en0006-70-22613 took: 2591\n",
      "Retrieving clueweb09-en0001-98-07420 took: 685\n",
      "Retrieving clueweb09-en0006-70-22583 took: 2754\n",
      "Retrieving clueweb09-en0011-71-15097 took: 2287\n",
      "Retrieving clueweb09-en0001-31-25150 took: 1625\n",
      "Retrieving clueweb09-en0006-70-22597 took: 2338\n",
      "Retrieving clueweb09-en0006-70-22616 took: 3137\n",
      "Retrieving clueweb09-enwp01-10-20426 took: 2087\n",
      "Retrieving clueweb09-en0004-12-04141 took: 3622\n",
      "Retrieving clueweb09-enwp01-40-22507 took: 1459\n",
      "Retrieving clueweb09-en0004-44-12378 took: 1739\n",
      "Retrieving clueweb09-en0001-39-05185 took: 3520\n",
      "Retrieving clueweb09-en0006-70-22608 took: 2545\n",
      "Retrieving clueweb09-en0002-83-01420 took: 1685\n",
      "Retrieving clueweb09-en0006-67-33539 took: 1356\n",
      "Retrieving clueweb09-enwp01-51-16785 took: 2425\n",
      "Retrieving clueweb09-en0006-70-22626 took: 4458\n",
      "Retrieving clueweb09-en0003-31-16634 took: 871\n",
      "Retrieving clueweb09-en0006-70-22566 took: 859\n",
      "Retrieving clueweb09-en0003-60-13052 took: 575\n",
      "Retrieving clueweb09-en0006-70-22577 took: 671\n",
      "Retrieving clueweb09-en0011-50-37385 took: 1561\n",
      "Retrieving clueweb09-en0010-88-00033 took: 2543\n",
      "Retrieving clueweb09-en0001-69-04553 took: 4963\n",
      "Retrieving clueweb09-en0011-55-26046 took: 1610\n",
      "Retrieving clueweb09-en0010-56-30018 took: 1922\n",
      "Retrieving clueweb09-en0002-46-20031 took: 947\n",
      "Retrieving clueweb09-en0006-70-22653 took: 3373\n",
      "Retrieving clueweb09-en0006-80-16991 took: 1015\n",
      "Retrieving clueweb09-en0011-65-28171 took: 2312\n",
      "Retrieving clueweb09-en0002-54-00468 took: 1997\n",
      "Retrieving clueweb09-en0010-70-04403 took: 3262\n",
      "Retrieving clueweb09-en0010-91-25089 took: 3927\n",
      "Retrieving clueweb09-en0006-97-01938 took: 1827\n",
      "Retrieving clueweb09-en0010-88-00029 took: 737\n",
      "Retrieving clueweb09-en0002-62-17931 took: 1735\n",
      "Retrieving clueweb09-en0010-91-25096 took: 2556\n",
      "Retrieving clueweb09-en0010-29-05959 took: 1117\n",
      "Retrieving clueweb09-en0010-91-25316 took: 778\n",
      "Retrieving clueweb09-en0007-20-34393 took: 1822\n",
      "Retrieving clueweb09-en0010-91-25094 took: 2200\n",
      "Retrieving clueweb09-en0002-62-17980 took: 1726\n",
      "Retrieving clueweb09-en0000-79-12800 took: 943\n",
      "Retrieving clueweb09-en0010-91-25513 took: 1995\n",
      "Retrieving clueweb09-en0010-29-05965 took: 2571\n",
      "Retrieving clueweb09-en0001-98-07429 took: 1977\n",
      "Retrieving clueweb09-en0001-25-08269 took: 2453\n",
      "Retrieving clueweb09-en0010-47-16457 took: 1574\n",
      "Retrieving clueweb09-en0000-61-21648 took: 1825\n",
      "Retrieving clueweb09-en0001-25-08270 took: 560\n",
      "Retrieving clueweb09-en0001-98-07434 took: 2144\n",
      "Retrieving clueweb09-en0000-11-36944 took: 590\n",
      "Retrieving clueweb09-en0001-31-23338 took: 1311\n",
      "Retrieving clueweb09-en0001-98-07435 took: 655\n",
      "Retrieving clueweb09-en0000-69-20179 took: 1975\n",
      "Retrieving clueweb09-en0000-21-12356 took: 1721\n",
      "Retrieving clueweb09-en0001-31-24515 took: 2842\n",
      "Retrieving clueweb09-en0000-78-19663 took: 2451\n",
      "Retrieving clueweb09-en0000-61-21508 took: 3179\n",
      "Retrieving clueweb09-en0001-31-24516 took: 3928\n",
      "Killed\n",
      "Process '/mnt/ceph/storage/data-in-progress/data-research/web-search/web-search-trec/trec-system-runs/trec20/web.adhoc//input.DFalah11.gz' to '/mnt/ceph/storage/data-in-progress/data-research/web-search/SIGIR-21/sigir21-deduplicate-trec-run-files/trec20-web.adhoc-top100/DFalah11.jsonl'.\n",
      "Process topic 101\n",
      "log4j:WARN No such property [maxBackupIndex] in org.apache.log4j.DailyRollingFileAppender.\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/workdir/copycat-cli/target/copycat-cli-1.0-SNAPSHOT-jar-with-dependencies.jar) to method sun.security.krb5.Config.getInstance()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Retrieving clueweb09-en0011-32-10292 took: 3293\n",
      "Retrieving clueweb09-en0008-37-05830 took: 3859\n",
      "Retrieving clueweb09-en0003-55-13061 took: 4649\n",
      "Retrieving clueweb09-en0008-80-29978 took: 4933\n",
      "Retrieving clueweb09-en0003-56-25754 took: 960\n",
      "Retrieving clueweb09-en0005-72-19341 took: 6055\n",
      "Retrieving clueweb09-en0008-90-16355 took: 1694\n",
      "Retrieving clueweb09-en0011-33-33396 took: 4105\n",
      "Retrieving clueweb09-en0005-80-12342 took: 1920\n",
      "Retrieving clueweb09-en0008-91-38053 took: 1635\n",
      "Retrieving clueweb09-en0008-44-25753 took: 4413\n",
      "Retrieving clueweb09-en0003-59-12273 took: 3210\n",
      "Retrieving clueweb09-en0011-37-21292 took: 1470\n",
      "Retrieving clueweb09-en0005-83-31893 took: 1940\n",
      "Retrieving clueweb09-en0008-54-15939 took: 2539\n",
      "Retrieving clueweb09-en0008-46-36824 took: 2613\n",
      "Retrieving clueweb09-en0006-10-11706 took: 2487\n",
      "Retrieving clueweb09-en0008-70-18084 took: 1990\n",
      "Retrieving clueweb09-en0011-14-40739 took: 4307\n",
      "Retrieving clueweb09-en0003-15-10031 took: 5528\n",
      "Retrieving clueweb09-en0008-49-26272 took: 3635\n",
      "Retrieving clueweb09-en0008-51-28018 took: 559\n",
      "Retrieving clueweb09-en0009-42-25680 took: 2693\n",
      "Retrieving clueweb09-en0006-27-08069 took: 3363\n",
      "Retrieving clueweb09-en0009-66-05308 took: 473\n",
      "Retrieving clueweb09-en0005-18-25249 took: 752\n",
      "Retrieving clueweb09-en0007-76-22839 took: 1732\n",
      "Retrieving clueweb09-en0003-49-12638 took: 2648\n",
      "Retrieving clueweb09-en0011-31-18804 took: 4321\n",
      "Retrieving clueweb09-en0010-01-14259 took: 2488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving clueweb09-en0005-47-05525 took: 2380\n",
      "Retrieving clueweb09-en0009-17-05283 took: 863\n",
      "Retrieving clueweb09-en0004-25-39469 took: 2548\n",
      "Retrieving clueweb09-en0008-12-29013 took: 2867\n",
      "Retrieving clueweb09-en0004-35-06637 took: 553\n",
      "Retrieving clueweb09-enwp01-10-20426 took: 2977\n",
      "Retrieving clueweb09-en0004-66-09322 took: 1578\n",
      "Retrieving clueweb09-en0009-39-27565 took: 2487\n",
      "Retrieving clueweb09-en0004-96-03965 took: 3007\n",
      "Retrieving clueweb09-enwp01-40-22507 took: 1340\n",
      "Retrieving clueweb09-en0005-12-03385 took: 625\n",
      "Retrieving clueweb09-en0007-65-08534 took: 4139\n",
      "Retrieving clueweb09-en0003-60-13052 took: 2561\n",
      "Retrieving clueweb09-en0007-07-23709 took: 2570\n",
      "Retrieving clueweb09-enwp01-53-17276 took: 2568\n",
      "Retrieving clueweb09-en0006-40-01877 took: 3329\n",
      "Retrieving clueweb09-en0007-11-10185 took: 1717\n",
      "Retrieving clueweb09-en0007-69-36189 took: 2690\n",
      "Retrieving clueweb09-en0006-41-29031 took: 948\n",
      "Retrieving clueweb09-en0006-28-35827 took: 1180\n",
      "Retrieving clueweb09-en0006-70-22626 took: 1520\n",
      "Retrieving clueweb09-en0004-04-28372 took: 4491\n",
      "Retrieving clueweb09-en0011-47-23750 took: 4299\n",
      "Retrieving clueweb09-en0006-34-06604 took: 2330\n",
      "Retrieving clueweb09-en0007-40-20313 took: 3449\n"
     ]
    }
   ],
   "source": [
    "RUN_FILE_DIR=EXPERIMENT_DIR + 'web-search-trec/trec-system-runs/trec20/web.adhoc/'\n",
    "OUTPUT_DIR=EXPERIMENT_DIR + 'SIGIR-21/sigir21-deduplicate-trec-run-files/trec20-web.adhoc-top100'\n",
    "\n",
    "def run_files_pretty():\n",
    "    ret = !ls $RUN_FILE_DIR\n",
    "    \n",
    "    return [i.replace('.gz', '').replace('input.', '') for i in ret]\n",
    "\n",
    "run_files_pretty()\n",
    "\n",
    "for run_file in run_files_pretty():\n",
    "    INPUT_FILE=RUN_FILE_DIR + '/input.' + run_file + '.gz'\n",
    "    OUTPUT_FILE=OUTPUT_DIR + '/' + run_file + '.jsonl'\n",
    "    print('Process \\'' + INPUT_FILE + '\\' to \\'' + OUTPUT_FILE + '\\'.')\n",
    "    \n",
    "    !../bash/copy-cat.sh \\\n",
    "        --output $OUTPUT_FILE \\\n",
    "        --input  $INPUT_FILE \\\n",
    "        --similarities \"url s3 cosine(3+5-grams) cosine(8-grams) cosine(1-grams) simhash(1-grams) simhash(3+5-grams) md5 text-profile\" \\\n",
    "        --s3Threshold 0.6 \\\n",
    "        --threads 5 \\\n",
    "        --ranks 100 \\\n",
    "        --documents ChatNoirMapfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/mnt/ceph/storage/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/ceph/storage/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SERP Deduplication\n",
    "\n",
    "- Situation:\n",
    "  - Near-Duplicates are removed from the Index\n",
    "    - With SimHash (3+5-grams) + Canonical-URL\n",
    "\n",
    "- Is it still necessary to remove near-duplicates from the SERP?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP: SERP Deduplication for a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specified output 'run-UAMSA10d2a8-deduplication.jsonl' exists.\r\n",
      "Skip...\r\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate a single run-file (please remove the output file to run copy-cat from scratch)\n",
    "\n",
    "!../bash/copy-cat.sh \\\n",
    "    --output run-UAMSA10d2a8-deduplication.jsonl \\\n",
    "    --input input.UAMSA10d2a8 \\\n",
    "    --similarities \"url s3 cosine(3+5-grams) cosine(8-grams) cosine(1-grams) simhash(1-grams) simhash(3+5-grams) md5 text-profile\" \\\n",
    "    --s3Threshold 0.7 \\\n",
    "    --threads 5 \\\n",
    "    --documents ChatNoirMapfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from trectools import TrecQrel\n",
    "\n",
    "qrels = TrecQrel('qrels.web.101-150.txt')\n",
    "\n",
    "def eval_with_threshold(threshold, run_file_name):\n",
    "    rows = []\n",
    "    with open(run_file_name) as jsonl_file:\n",
    "        for jsonl in jsonl_file:\n",
    "            dedup_data = json.loads(jsonl)\n",
    "            topic = dedup_data['topic']\n",
    "            judged_docs = qrels.get_document_names_for_topic(int(topic))\n",
    "            \n",
    "            for sim in dedup_data['similarities']:\n",
    "                is_judged = sim['firstId'] in judged_docs or sim['secondId'] in judged_docs\n",
    "                is_relevant = False\n",
    "                is_irrelevant = False\n",
    "                \n",
    "                if is_judged:\n",
    "                    judgment_a = qrels.get_judgement(sim['firstId'], int(topic))\n",
    "                    judgment_b = qrels.get_judgement(sim['secondId'], int(topic))\n",
    "                    is_irrelevant = judgment_a == 0 or judgment_b == 0\n",
    "                    is_relevant = not is_irrelevant\n",
    "                \n",
    "                rows += [{\n",
    "                    'topic': topic,\n",
    "                    'judged': is_judged,\n",
    "                    'relevant': is_relevant,\n",
    "                    'irrelevant': is_irrelevant,\n",
    "                    'near-duplicate': sim['similarities']['s3'] >=  threshold,\n",
    "                    'simhash(3+5-grams)': sim['similarities']['simhash(3+5-grams)'] > 0.94,\n",
    "                    'simhash(1-grams)': sim['similarities']['simhash(1-grams)'] > 0.94,\n",
    "                    'url': sim['similarities']['url'] > 0.5,\n",
    "                    'text-profile': sim['similarities']['text-profile'] > 0.5,\n",
    "                    'md5': sim['similarities']['md5'] > 0.5,\n",
    "                    'copy-cat': ((sim['similarities']['simhash(3+5-grams)'] > 0.94) or ((sim['similarities']['url'] > 0.5) and (sim['similarities']['simhash(1-grams)'] > 0.94))),\n",
    "                    'copy-cat-tp': ((sim['similarities']['simhash(3+5-grams)'] > 0.94) or (sim['similarities']['text-profile'] > 0.5) or ((sim['similarities']['url'] > 0.5) and (sim['similarities']['simhash(1-grams)'] > 0.94)))\n",
    "                }]\n",
    "\n",
    "    return rows\n",
    "\n",
    "def eval_runs_with_threshold(threshold, run_files):\n",
    "    rows = []\n",
    "    for r in run_files:\n",
    "        rows += eval_with_threshold(threshold, r)\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEDUP_TARGET_DIR='../../../top-100-deduplication/'\n",
    "ALL_DIRS=!ls $DEDUP_TARGET_DIR\n",
    "ALL_DIRS=!ls $DEDUP_TARGET_DIR\n",
    "ALL_DIRS = [DEDUP_TARGET_DIR + i for i in ALL_DIRS]\n",
    "\n",
    "\n",
    "df = eval_runs_with_threshold(0.82, ALL_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision/Recall with S3 score as ground-truth (small cw09 sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Top100</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Relevant@Top100</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Irrelevant@Top100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CopyCat</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimHash(1-grams)</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SimHash(3+5-grams)</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextProfile</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.383</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MD5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Approach    Top100        Relevant@Top100         \\\n",
       "                      Precision Recall       Precision Recall   \n",
       "0             CopyCat     0.997  0.701           0.998  0.836   \n",
       "1    SimHash(1-grams)     0.932  0.792           0.952  0.961   \n",
       "2  SimHash(3+5-grams)     0.998  0.589           1.000  0.689   \n",
       "3         TextProfile     0.998  0.305           0.996  0.383   \n",
       "4                 MD5     1.000  0.135           1.000  0.239   \n",
       "\n",
       "  Irrelevant@Top100         \n",
       "          Precision Recall  \n",
       "0             0.996  0.634  \n",
       "1             0.958  0.759  \n",
       "2             0.997  0.537  \n",
       "3             1.000  0.250  \n",
       "4             1.000  0.147  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_score(df, approach):\n",
    "    from sklearn.metrics import precision_score\n",
    "    return \"{:0.3f}\".format(precision_score(y_true=df['near-duplicate'], y_pred=df[approach]))\n",
    "\n",
    "def recall_score(df, approach):\n",
    "    from sklearn.metrics import recall_score\n",
    "    return \"{:0.3f}\".format(recall_score(y_true=df['near-duplicate'], y_pred=df[approach]))\n",
    "\n",
    "def table_row(df, approach, approach_display_name):\n",
    "    df_relevant_100 = df[(df['judged']) & (df['relevant'])]\n",
    "    df_irrelevant_100 = df[(df['judged']) & (~df['relevant'])]\n",
    "\n",
    "    return {\n",
    "        'Approach': approach_display_name,\n",
    "        'Precision (Top100)': precision_score(df, approach),\n",
    "        'Recall (Top100)': recall_score(df, approach),\n",
    "        'Precision (Relevant@Top100)': precision_score(df_relevant_100, approach),\n",
    "        'Recall (Relevant@Top100': recall_score(df_relevant_100, approach),\n",
    "        'Precision (Irrelevant@Top100)': precision_score(df_irrelevant_100, approach),\n",
    "        'Recall (Irrelevant@Top100)': recall_score(df_irrelevant_100, approach),\n",
    "    }\n",
    "\n",
    "def report_table(df):\n",
    "    rows = []\n",
    "    for approach, approach_display_name in [('copy-cat-tp', 'CopyCat'), ('simhash(1-grams)', 'SimHash(1-grams)'), ('simhash(3+5-grams)', 'SimHash(3+5-grams)'), ('text-profile', 'TextProfile') , ('md5', 'MD5')]:\n",
    "        rows += [table_row(df, approach, approach_display_name)]\n",
    "    ret = pd.DataFrame(rows)\n",
    "    ret.set_index('Approach', inplace=True)\n",
    "    ret.columns = pd.MultiIndex.from_tuples([\n",
    "        ('Top100', 'Precision'), ('Top100', 'Recall'),\n",
    "        ('Relevant@Top100', 'Precision'), ('Relevant@Top100', 'Recall'),\n",
    "        ('Irrelevant@Top100', 'Precision'), ('Irrelevant@Top100', 'Recall'),\n",
    "    ])\n",
    "\n",
    "    return ret.reset_index()\n",
    "\n",
    "print('Precision/Recall with S3 score as ground-truth (small cw09 sample):')\n",
    "report_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "- Improve efficiency of \"local\" copy-cat\n",
    "- Evaluations:\n",
    "  - Add top 1000 to the table above\n",
    "  - At which Positions occur duplicates?\n",
    "    - Duplicates within the top k\n",
    "- Evaluation Notebooks (all available runs):\n",
    "  - ClueWeb\n",
    "  - Robust04\n",
    "  - Argsme\n",
    "- Relevance Transfer:\n",
    "  - Deduplicate on the top-10000 results for each topic with CopyCat\n",
    "- Finish Anserini-Integration\n",
    "  - Use jigsaw modules to separate ChatNoir from Anserini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
